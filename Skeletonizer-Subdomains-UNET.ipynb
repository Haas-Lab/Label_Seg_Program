{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:01:20.918701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-24 11:01:21.227624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-24 11:01:21.227639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-24 11:01:21.266133: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-24 11:01:21.953658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-24 11:01:21.953759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-24 11:01:21.953765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mplc\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import numpy.ma as ma \n",
    "import napari\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from aicsimageio import AICSImage, imread \n",
    "from scipy.ndimage import center_of_mass\n",
    "from scipy.ndimage import shift as img_shift\n",
    "from scipy.signal import correlate2d\n",
    "from scipy.signal import correlate2d\n",
    "from math import isclose \n",
    "from scipy.stats.mstats import pearsonr\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.io import imsave\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.morphology import medial_axis, skeletonize,binary_closing, skeletonize_3d,dilation, erosion, remove_small_objects\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.segmentation import flood_fill\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import color\n",
    "from sklearn import neighbors\n",
    "from scipy.spatial import distance, KDTree\n",
    "from skimage import data, util, filters, color\n",
    "from skimage.segmentation import watershed, random_walker\n",
    "import skimage.measure as measure\n",
    "# import processing functions\n",
    "from processing.processing_functions import *\n",
    "\n",
    "from DouglasPeucker import DouglasPeucker\n",
    "\n",
    "\n",
    "\n",
    "# import machine learning modules\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.inferers.inferer import SliceInferer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change output figure size\n",
    "# ...needs to be in its own cell for some reason...\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image for Segementaion\n",
    "IMAGE = 'pyNeuroDCNN/00_Live6-7-2018_08-53-23.tif'\n",
    "\n",
    "# Min Pixel Length for Seg\n",
    "PIX = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(image, mode, spatial_dim):\n",
    "    path = os.getcwd()\n",
    "\n",
    "    if spatial_dim == 3:\n",
    "        # use AI assistance\n",
    "        lateral_steps = 64\n",
    "        axial_steps = 16\n",
    "        patch_size = (axial_steps, lateral_steps, lateral_steps)\n",
    "        batch_size = 64\n",
    "        dim_order = (0,4,1,2,3)\n",
    "        orig_shape = image.shape\n",
    "        \n",
    "        patch_transform = transforms.Compose([MinMaxScalerVectorized(),\n",
    "                                patch_imgs(xy_step = lateral_steps, z_step = axial_steps, patch_size = patch_size, is_mask = False)])\n",
    "\n",
    "        processed_test_img = MyImageDataset(raw_img = image,\n",
    "                                            transform = patch_transform,\n",
    "                                            img_order = dim_order)\n",
    "        \n",
    "        # img_dataloader = DataLoader(processed_test_img, batch_size = 1)\n",
    "\n",
    "        reconstructed_img = inference(processed_test_img,f'{path}/models/{mode}.onnx', batch_size, patch_size, orig_shape)\n",
    "        reconstructed_img = reconstructed_img.astype(int)\n",
    "\n",
    "        # soma category is inferenced for only \"Neuron\" => change all the soma labels (1) to dendrite labels (2)\n",
    "        if len(np.unique(reconstructed_img)) == 2:\n",
    "            reconstructed_img[reconstructed_img==1] = 2\n",
    "            return reconstructed_img, len(np.unique(reconstructed_img))+1\n",
    "        else:\n",
    "            return reconstructed_img, len(np.unique(reconstructed_img))\n",
    "\n",
    "    if spatial_dim == 2:\n",
    "        # currently lateral steps are fixed as 512 due to the model being trained on full slices of 512x512.\n",
    "        model_path = f'{path}/models/2D_{mode}.pth'\n",
    "\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        lateral_steps = 512\n",
    "        patch_size = (lateral_steps, lateral_steps)\n",
    "        batch_size = 1\n",
    "        input_chnl = 1\n",
    "        output_chnl = 4\n",
    "        norm_type = \"batch\"\n",
    "        dropout = 0.1\n",
    "\n",
    "        model = UNet(spatial_dims=2, \n",
    "                    in_channels = input_chnl,\n",
    "                    out_channels = output_chnl,\n",
    "                    channels = (32, 64, 128, 256, 512),\n",
    "                    strides=(2, 2, 2, 2),\n",
    "                    num_res_units=2,\n",
    "                    norm = norm_type,\n",
    "                    dropout = dropout)\n",
    "\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(\"cpu\")\n",
    "        inferer = SliceInferer(roi_size=patch_size, sw_batch_size=batch_size, spatial_dim = 0, progress = True)\n",
    "\n",
    "        raw_transform = transforms.Compose([MinMaxScalerVectorized()])\n",
    "        processed_img_dataset = WholeVolumeDataset(raw_img=image,\n",
    "                                           raw_transform=raw_transform)\n",
    "        \n",
    "        processed_img, _ = next(iter(processed_img_dataset))\n",
    "        processed_img = torch.unsqueeze(processed_img, dim = 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = inferer(inputs = processed_img, network=model)\n",
    "            print(output.shape)\n",
    "            probabilities = torch.softmax(output,1)\n",
    "            print(probabilities.shape)\n",
    "            pred = to_numpy(torch.argmax(probabilities, 1)).astype(np.int16)\n",
    "\n",
    "        # soma category is inferenced for only \"Neuron\" => change all the soma labels (1) to dendrite labels (2)\n",
    "        if len(np.unique(pred)) == 2:\n",
    "            pred[pred==1] = 2\n",
    "            return pred, len(np.unique(pred))+1\n",
    "        else:\n",
    "            return pred, len(np.unique(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 512, 512)\n",
      "reading in existing image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 190/190 [00:31<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 190, 512, 512])\n",
      "torch.Size([1, 4, 190, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "data1 = imread(IMAGE)\n",
    "img_slice = data1[ 0, 0, :, :, :]\n",
    "print(img_slice.shape)\n",
    "labels, other = model_predict(img_slice,\"Soma+Dendrite\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels==3]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels' at 0x7fc566022dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-24 11:03:13,084 - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "results_viewer = napari.Viewer()\n",
    "results_viewer.add_image(data1)\n",
    "results_viewer.add_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnpoints_3D(array):\n",
    "    test_array =array.copy()\n",
    "    window = np.zeros([3,3])\n",
    "    points = []\n",
    "    for z in range(test_array.shape[0]):\n",
    "        for i in range(512-3):\n",
    "            for j in range(512-3):\n",
    "                if test_array[z,i+1,j+1]==1:\n",
    "                    window=test_array[z,i:i+3, j:j+3]\n",
    "                    if np.sum(window)<=3:\n",
    "                        if False ==((window[0,0]==True and window[2,2]==True) or (window[0,2]==True and window[2,0]==True)):\n",
    "\n",
    "                            if np.sum(window[1,:])<=2 and  np.sum(np.sum(window[:,1]))<=2:\n",
    "                                points.append((z,i+1,j+1))\n",
    "    return points\n",
    "                                              \n",
    "                                              \n",
    "def returnpoints_2D(array):\n",
    "    test_array =array.copy()\n",
    "    window = np.zeros([3,3])\n",
    "    points = []\n",
    "    for i in range(512-3):\n",
    "        for j in range(512-3):\n",
    "            if test_array[i+1,j+1]==1:\n",
    "                window=test_array[i:i+3, j:j+3]\n",
    "                if np.sum(window)<=3:\n",
    "                    if False ==((window[0,0]==True and window[2,2]==True) or (window[0,2]==True and window[2,0]==True)):\n",
    "\n",
    "                        if np.sum(window[1,:])<=2 and  np.sum(np.sum(window[:,1]))<=2:\n",
    "                            points.append((j+1,i+1))\n",
    "    return points\n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an directory to store outputs:\n",
    "if not os.path.exists('results/'):\n",
    "    os.makedirs('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keys for the pixel classification results:\n",
    "* 0 - Background\n",
    "* 1 - Soma\n",
    "* 2 - Dendrites\n",
    "* 3 - Junk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Threshold and mask the image\\nthreshold_image = image.copy()\\nimg_thresh = threshold_otsu(image)\\nthreshold_image[threshold_image< img_thresh]= 0\\nthreshold_image[threshold_image>0]= 1\\ngau_thresh_img = gaussian(threshold_image.copy())\\ngau_thresh_img2 = gau_thresh_img.copy()\\ngau_thresh_img2[gau_thresh_img2>(img_thresh*.1)]=1\\n\\n# Inspect the neuron\\ntest = napari.Viewer()\\ntest.add_image(image, name='Image', scale=(5, 1, 1), colormap='gray', blending='additive')\\ntest.add_image(gau_thresh_img2, name='Gau Image',  scale=(5, 1, 1), colormap='green', blending='additive')\\ntest.add_image(gau_thresh_img, name='Threshold Image', scale=(5, 1, 1), colormap='gray', blending='additive')\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Threshold and mask the image\n",
    "threshold_image = image.copy()\n",
    "img_thresh = threshold_otsu(image)\n",
    "threshold_image[threshold_image< img_thresh]= 0\n",
    "threshold_image[threshold_image>0]= 1\n",
    "gau_thresh_img = gaussian(threshold_image.copy())\n",
    "gau_thresh_img2 = gau_thresh_img.copy()\n",
    "gau_thresh_img2[gau_thresh_img2>(img_thresh*.1)]=1\n",
    "\n",
    "# Inspect the neuron\n",
    "test = napari.Viewer()\n",
    "test.add_image(image, name='Image', scale=(5, 1, 1), colormap='gray', blending='additive')\n",
    "test.add_image(gau_thresh_img2, name='Gau Image',  scale=(5, 1, 1), colormap='green', blending='additive')\n",
    "test.add_image(gau_thresh_img, name='Threshold Image', scale=(5, 1, 1), colormap='gray', blending='additive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 190, 512, 512)\n",
      "Skeltonize in 3D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Segments' at 0x7fc57cc12dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seg_skel(image, img2skel, twoD=True):\n",
    "    # Takes an skeletonized image and segments the skeleton per plan\n",
    "    # Returns segs as unique values in 3D array\n",
    "    \n",
    "    # 3D per volume\n",
    "    if twoD==False:\n",
    "        print('Skeltonize in 3D')\n",
    "        skel = skeletonize_3d(neuron_mask)\n",
    "    \n",
    "    # 2D per plane\n",
    "    if twoD==True:\n",
    "        img2skel = img2skel/np.max(img2skel)\n",
    "        skel = np.zeros(img2skel.shape)\n",
    "        for u in range(img2skel.shape[0]):\n",
    "            skel[u,:,:]  = skeletonize(img2skel[u,:,:])\n",
    "    segsperplane = np.zeros(image.shape)\n",
    "    for i in range(skel.shape[0]):\n",
    "        edges = filters.sobel(skel[i,:,:])\n",
    "        plane = skel[i,:,:]\n",
    "        seeds = np.zeros((512,512))\n",
    "        foreground, background = 1, 2\n",
    "        seeds[plane <.5] = background\n",
    "        seeds[skel[i,:,:] > .5] = foreground\n",
    "        ws = watershed(edges, seeds)\n",
    "        segments = measure.label(ws == foreground)\n",
    "        temp_max = np.max(segsperplane)\n",
    "        segments = segments+temp_max\n",
    "        segments[segments ==temp_max]=0\n",
    "        segsperplane[i,:,:] = segments\n",
    "    return segsperplane\n",
    "\n",
    "image = data1[0,0,:,:,:]\n",
    "print(labels.shape)\n",
    "dendrites = np.zeros_like(labels[0,:,:,:])\n",
    "dendrites[labels[0,:,:,:]==2]=1\n",
    "dendrites = np.array(dendrites, bool)\n",
    "dendrites = remove_small_objects(dendrites, 500, connectivity=10)\n",
    "test = napari.Viewer()\n",
    "test.add_image(dendrites, name='Neuron', scale=(5, 1, 1), colormap='magenta', blending='additive')\n",
    "\n",
    "# Select feature to segment\n",
    "neuron_mask = dendrites\n",
    "# Run segmentation and skeletonization\n",
    "segsperplane = seg_skel(image, dendrites, False)\n",
    "segsperplane = segsperplane.astype(int)\n",
    "# Inspect results\n",
    "test = napari.Viewer()\n",
    "test.add_image(neuron_mask, name='Neuron', scale=(5, 1, 1), colormap='magenta', blending='additive')\n",
    "test.add_labels(segsperplane, name='Segments', scale=(5, 1, 1), blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locationMinus(A, B):\n",
    "    return (A[0] - B[0], A[1] - B[1])\n",
    "\n",
    "def normDelta(p1, p2):\n",
    "    x, y = locationMinus(p1, p2)\n",
    "    sz = math.sqrt(x*x + y*y)\n",
    "    if sz ==0:\n",
    "        sz=1\n",
    "    return (x/sz, y/sz,)\n",
    "\n",
    "# Given a selected point and an additional neightboring point\n",
    "# returns a point perpendicular to the line joining these points\n",
    "def caliperPoints(origin, point, ifNext):\n",
    "    x, y =  normDelta(point, origin)\n",
    "    if ifNext:\n",
    "        vector = np.array([y, -x])\n",
    "    else:\n",
    "        vector = np.array([-y, x])\n",
    "    return vector\n",
    "\n",
    "def return_corners(firstP, secP):\n",
    "\n",
    "    pC = caliperPoints(firstP, secP, ifNext=False)\n",
    "    pCprime = pC * 3\n",
    "    radiiPoint = pCprime+firstP\n",
    "    negRadiiPoint = -pCprime +firstP\n",
    "\n",
    "    negX = int(negRadiiPoint[0])\n",
    "    posX = int(radiiPoint[0])\n",
    "    posY = int(negRadiiPoint[1])\n",
    "    negY = int(radiiPoint[1])\n",
    "    \n",
    "\n",
    "    \n",
    "    return(negX, posY, posX, negY)\n",
    "\n",
    "def segmentGen(t1, t2, plane):\n",
    "\n",
    "\n",
    "    x1, y1, x2, y2 = return_corners(t1, t2)\n",
    "    x3, y3, x4, y4 = return_corners(t2, t1)\n",
    "\n",
    "\n",
    "    polygon = [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n",
    "\n",
    "    img = Image.new('L', (512, 512), 0)\n",
    "    ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "    block = np.array(img)\n",
    "    binary_image = plane.copy()\n",
    "    binary_image[binary_image>0]=1\n",
    "    segment = block*binary_image\n",
    "    return block, segment\n",
    "\n",
    "def return_smaller_seg(p1, p2, threshold, midpoints):\n",
    "    if round(math.hypot(p1[1] - p2[1], p1[0] - p2[0])) > threshold:\n",
    "        mp = (round((p1[0] + p2[0])/2), round((p1[1] + p2[1])/2))\n",
    "        fp = p1\n",
    "        subpoint1 = return_smaller_seg(fp, mp, threshold, midpoints)\n",
    "        if subpoint1 is False:\n",
    "            midpoints.append(mp)\n",
    "        sp = p2\n",
    "        subpoint2 = return_smaller_seg(mp, sp, threshold, midpoints)\n",
    "         \n",
    "        if subpoint2 is False:\n",
    "            midpoints.append(mp)\n",
    "        return midpoints\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skeleton_points(points, skelly_image):\n",
    "    skelly_image[skelly_image>0]=1\n",
    "    end_points = []\n",
    "    y_points = []\n",
    "\n",
    "    for point in range(points[0].shape[0]):\n",
    "        i = points[0][point]\n",
    "        j = points[1][point]\n",
    "        window=skelly_image[i-1:i+2, j-1:j+2]\n",
    "        '''        if False ==((window[0,0]==True and window[2,2]==True) or (window[0,2]==True and window[2,0]==True)):\n",
    "            if np.sum(window[1,:])<=2 and  np.sum(np.sum(window[:,1]))<=2:\n",
    "                end_points.append((j,i))'''\n",
    "        if np.sum(window)<=2:\n",
    "            end_points.append((j,i))\n",
    "        if np.sum(window)==4:\n",
    "            y_points.append((j,i))\n",
    "    #end_points = np.array(end_points)\n",
    "    #y_points   = np.array(y_points)\n",
    "    return end_points, y_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start timer to measure segmentation time\n",
    "start = time.time()\n",
    "\n",
    "SLAP_ROI = np.zeros(segsperplane.shape)\n",
    "SLAP_Blocks = np.zeros(segsperplane.shape)\n",
    "roi_ID = 2\n",
    "DP_Value = 1\n",
    "for z in range(segsperplane.shape[0]):\n",
    "    \n",
    "    \n",
    "    segs_colors = np.unique(segsperplane[z,:,:]).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in segs_colors[1:]:\n",
    "        plane = segsperplane[z,:,:].copy()\n",
    "        plane[plane !=i]=0\n",
    "        plane[plane>0]=1\n",
    "        points = np.where(plane==1)\n",
    "\n",
    "        endpoints, junctions = find_skeleton_points(points, plane)\n",
    "\n",
    "\n",
    "        if len(junctions) > 0:\n",
    "            #print(\"this many y-junctions\", len(junctions))\n",
    "            for junc in junctions:\n",
    "                plane[junc[1], junc[0]] = 0\n",
    "            line_fragments = measure.label(plane)\n",
    "\n",
    "            cut_lines = np.unique(line_fragments).astype(int)\n",
    "            for line in cut_lines[1:]:\n",
    "                subplane = line_fragments.copy()\n",
    "\n",
    "                subplane[subplane !=line]=0\n",
    "                subplane[subplane>0]=1\n",
    "\n",
    "                points = np.where(subplane==1)\n",
    "\n",
    "                endpoints, junctions = find_skeleton_points(points, plane)\n",
    "\n",
    "                if len(endpoints)>1:\n",
    "                    #print(endpoints)\n",
    "                    points  = list(zip(points[1], points[0]))\n",
    "                    points =  DouglasPeucker(points, 1)\n",
    "                    pointArray = np.array(points)\n",
    "                    sortedPoints = np.zeros_like(pointArray)\n",
    "                    kdTree = KDTree(pointArray)\n",
    "                    for i, c in enumerate(kdTree.query([0,0], k=pointArray.shape[0])[1]):\n",
    "                        sortedPoints[i, : ] = pointArray[c, :]\n",
    "\n",
    "                    for v in range(sortedPoints.shape[0]-1):\n",
    "                        block, _ =  segmentGen(sortedPoints[v,:], sortedPoints[v+1,:], dendrites[z, :, :])\n",
    "                        flipped =block\n",
    "                        oneSeg = flipped*dendrites[z, :, :]\n",
    "                        oneSeg = dilation(oneSeg)\n",
    "                        flipped[flipped >0]= roi_ID\n",
    "                        oneSeg[oneSeg >0]= roi_ID\n",
    "                        roi_ID += 1\n",
    "                        SLAP_Blocks[z, :, :] = SLAP_Blocks[z, :, :] + flipped\n",
    "                        SLAP_ROI[z, :, :] = SLAP_ROI[z, :, :] + oneSeg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(endpoints)>1:\n",
    "            points = np.where(plane==1)\n",
    "            points  = list(zip(points[1], points[0]))\n",
    "            points =  DouglasPeucker(points, 1)\n",
    "            pointArray = np.array(points)\n",
    "            sortedPoints = np.zeros_like(pointArray)\n",
    "            kdTree = KDTree(pointArray)\n",
    "            for i, c in enumerate(kdTree.query([0,0], k=pointArray.shape[0])[1]):\n",
    "                sortedPoints[i, : ] = pointArray[c, :]\n",
    "\n",
    "            for v in range(sortedPoints.shape[0]-1):\n",
    "                block, _ =  segmentGen(sortedPoints[v,:], sortedPoints[v+1,:], dendrites[z, :, :])\n",
    "                flipped =block\n",
    "                oneSeg = flipped*dendrites[z, :, :]\n",
    "                oneSeg = dilation(oneSeg)\n",
    "                flipped[flipped >0]= roi_ID\n",
    "                oneSeg[oneSeg >0]= roi_ID\n",
    "                roi_ID += 1\n",
    "                SLAP_Blocks[z, :, :] = SLAP_Blocks[z, :, :] + flipped\n",
    "                SLAP_ROI[z, :, :] = SLAP_ROI[z, :, :] + oneSeg\n",
    "\n",
    "soma = labels[0,:,:,:].copy()\n",
    "soma[labels[0,:,:,:]!=1]=0\n",
    "soma = np.array(soma, bool)\n",
    "soma = remove_small_objects(soma,250, connectivity=2)\n",
    "SLAP_ROI[soma==1]=1                    \n",
    "SLAP_ROI = SLAP_ROI.astype(int)   \n",
    "SLAP_Blocks = SLAP_Blocks.astype(int)\n",
    "\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed:  10.458990812301636\n"
     ]
    }
   ],
   "source": [
    "print('Time Elapsed: ', end - start)\n",
    "neuron_image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'ROI' at 0x7fc567f6fd00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = napari.Viewer()\n",
    "test.add_image(neuron_image, name='Neuron', scale=(5, 1, 1), colormap='gray', blending='additive')\n",
    "#test.add_labels(segsperplane, name='Segments', scale=(5, 1, 1), blending='additive')\n",
    "test.add_labels(SLAP_ROI, name='ROI', scale=(5, 1, 1), color=labelColorDict, blending='additive')\n",
    "#test.add_labels(SLAP_Blocks, name='Blocks', scale=(5, 1, 1), blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelColorDict = {}\n",
    "labelColorDict[0] = (0,0,0)\n",
    "_max = np.max(SLAP_ROI)\n",
    "for labelInt in np.unique(SLAP_ROI):\n",
    "    cmap = cm.Spectral(labelInt/_max)\n",
    "    labelColorDict[labelInt] = (cmap[0],cmap[1],cmap[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.add_labels(dendrites, name='Blocks', scale=(5, 1, 1), blending='additive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.zeros((len(np.unique(SLAP_ROI)), 3))\n",
    "for index, labelID in enumerate(np.unique(SLAP_ROI)):\n",
    "    com_measure = np.zeros_like(SLAP_ROI)\n",
    "    com_measure[SLAP_ROI==labelID] = 1\n",
    "    points[index, :] = center_of_mass(com_measure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=3, algorithm='brute').fit(points)\n",
    "distances, indices = nbrs.kneighbors(points)\n",
    "indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "for index in range(indices.shape[0]):\n",
    "    z = [points[indices[index, 0], 0], points[indices[index, 1], 0]]\n",
    "    x = [points[indices[index, 0], 1], points[indices[index, 1], 1]]\n",
    "    y = [points[indices[index, 0], 2], points[indices[index, 1], 2]]\n",
    "    ax.plot(x, y, z, label='parametric curve')\n",
    "    \n",
    "    z = [points[indices[index, 0], 0], points[indices[index, 2], 0]]\n",
    "    x = [points[indices[index, 0], 1], points[indices[index, 2], 1]]\n",
    "    y = [points[indices[index, 0], 2], points[indices[index, 2], 2]]\n",
    "    ax.plot(x, y, z, label='parametric curve')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
